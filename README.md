# ğŸ¬ ViralVibe - Viral Video Repurposing SaaS

> **Transform long-form content into viral short-form clips automatically**

ViralVibe is a production-ready SaaS platform that competes with OpusClip and WayinVideo. It uses AI to analyze long-form videos, identify viral moments, and automatically generate optimized short-form clips with dynamic layouts, animated captions, and visual effects.

---

## âœ¨ Key Features

- ğŸ¥ **YouTube URL & File Upload Support** - Process videos from URLs or direct uploads
- ğŸ¤– **AI-Powered Virality Scoring** - Identify the most engaging moments using multi-factor analysis
- ğŸ“ **Word-Level Transcription** - WhisperX integration for precise captions
- ğŸ‘¤ **Active Speaker Detection** - Automatic face tracking and dynamic cropping
- ğŸ¨ **Remotion Video Rendering** - Real-time preview and export with custom layouts
- ğŸ“Š **Audio & Visual Analysis** - Energy detection and saliency mapping
- ğŸ’¬ **Hook Extraction** - LLM-powered identification of engagement triggers
- âš¡ **GPU-Accelerated Processing** - Modal functions for fast video processing
- ğŸ” **Complete Authentication** - Supabase Auth with JWT tokens
- ğŸ“¦ **Production Ready** - Docker, CI/CD, comprehensive error handling

---

## ğŸ—ï¸ Architecture

```
viralvibe-saas/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ web/              # Next.js 14 Frontend (App Router)
â”‚   â””â”€â”€ api/              # FastAPI Backend
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ worker/           # Modal GPU Functions
â”‚   â”œâ”€â”€ shared/           # Shared TypeScript Types
â”‚   â””â”€â”€ db/               # Supabase Migrations
â”œâ”€â”€ docker-compose.yml    # Local Development Stack
â”œâ”€â”€ pnpm-workspace.yaml   # Monorepo Configuration
â””â”€â”€ pyproject.toml        # Python Dependencies
```

### Tech Stack

#### Frontend
- **Framework**: Next.js 14 (App Router, Server Components)
- **Language**: TypeScript (strict mode)
- **Styling**: Tailwind CSS
- **UI Components**: shadcn/ui
- **Video Rendering**: Remotion
- **State Management**: React Query, Context API
- **Auth**: Supabase Auth

#### Backend
- **Framework**: FastAPI (async)
- **Language**: Python 3.10
- **Database**: PostgreSQL (via Supabase)
- **Task Queue**: Celery + Redis
- **Validation**: Pydantic v2
- **Auth**: JWT tokens

#### Video Processing
- **Infrastructure**: Modal (GPU functions)
- **Transcription**: WhisperX
- **Speaker Detection**: Pyannote.audio
- **Video Processing**: FFmpeg, OpenCV
- **Audio Analysis**: Librosa
- **LLM**: OpenAI GPT-4o

#### Infrastructure
- **Cloud Storage**: AWS S3
- **Database**: Supabase (PostgreSQL + Row-Level Security)
- **Caching**: Redis
- **Deployment**: Vercel (frontend), Railway/Render (backend), Modal (workers)

---

## ğŸš€ Quick Start

### Prerequisites

- **Node.js** >= 20.0.0
- **pnpm** >= 8.0.0
- **Python** >= 3.10
- **Docker** & **Docker Compose**
- **Supabase** account
- **Modal** account
- **OpenAI** API key

### 1. Clone & Install

```bash
# Clone the repository
git clone https://github.com/yourusername/viralvibe-saas.git
cd viralvibe-saas

# Install dependencies
pnpm install

# Install Python dependencies
pip install -e .
```

### 2. Environment Setup

```bash
# Copy environment template
cp .env.example .env

# Edit .env and fill in your credentials:
# - Supabase URL and keys
# - Modal tokens
# - OpenAI API key
# - AWS S3 credentials
```

### 3. Database Setup

```bash
# Run Supabase migrations
cd packages/db
pnpm run migrate
```

### 4. Start Development Environment

```bash
# Option A: Using Docker (Recommended)
docker-compose up -d

# Option B: Manual start
# Terminal 1: Start backend
cd apps/api
uvicorn main:app --reload

# Terminal 2: Start Celery worker
cd apps/api
celery -A tasks.celery_app worker --loglevel=info

# Terminal 3: Start frontend
cd apps/web
pnpm dev
```

### 5. Access the Application

- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs

---

## ğŸ“‹ Project Structure

### `/apps/web` - Next.js Frontend

```
apps/web/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ (auth)/
â”‚   â”‚   â”œâ”€â”€ login/
â”‚   â”‚   â””â”€â”€ signup/
â”‚   â””â”€â”€ (protected)/
â”‚       â””â”€â”€ dashboard/
â”‚           â”œâ”€â”€ page.tsx              # Video list
â”‚           â”œâ”€â”€ upload/               # Upload interface
â”‚           â”œâ”€â”€ video/[id]/           # Video detail
â”‚           â””â”€â”€ exports/              # Exports list
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ui/                          # shadcn/ui components
â”‚   â”œâ”€â”€ layouts/                     # Header, Sidebar
â”‚   â”œâ”€â”€ VideoCard.tsx                # Video display card
â”‚   â”œâ”€â”€ ClipCard.tsx                 # Clip display card
â”‚   â””â”€â”€ Remotion/                    # Remotion compositions
â”‚       â”œâ”€â”€ Composition.tsx
â”‚       â”œâ”€â”€ DynamicCropVideo.tsx
â”‚       â”œâ”€â”€ AnimatedCaptions.tsx
â”‚       â””â”€â”€ AudioVisualization.tsx
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ api/                         # API client
â”‚   â”œâ”€â”€ hooks/                       # Custom React hooks
â”‚   â””â”€â”€ utils/                       # Helper functions
â””â”€â”€ middleware.ts                    # Auth middleware
```

### `/apps/api` - FastAPI Backend

```
apps/api/
â”œâ”€â”€ main.py                          # FastAPI app entry point
â”œâ”€â”€ config.py                        # Environment configuration
â”œâ”€â”€ database.py                      # SQLAlchemy setup
â”œâ”€â”€ models.py                        # Pydantic models
â”œâ”€â”€ middleware/
â”‚   â””â”€â”€ auth.py                      # JWT validation
â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ auth.py                      # Login/signup
â”‚   â”œâ”€â”€ videos.py                    # Video CRUD
â”‚   â”œâ”€â”€ clips.py                     # Clip gallery
â”‚   â””â”€â”€ exports.py                   # Export management
â”œâ”€â”€ tasks/
â”‚   â”œâ”€â”€ celery_app.py                # Celery configuration
â”‚   â””â”€â”€ video_processing.py          # Background tasks
â””â”€â”€ utils/
    â”œâ”€â”€ validators.py                # Input validation
    â””â”€â”€ errors.py                    # Custom exceptions
```

### `/packages/worker` - Modal GPU Functions

```
packages/worker/
â”œâ”€â”€ video_processor.py               # Main Modal function
â”œâ”€â”€ yt_dlp_downloader.py             # Video download
â”œâ”€â”€ whisperx_processor.py            # Transcription
â”œâ”€â”€ pyannote_asd.py                  # Speaker detection
â”œâ”€â”€ audio_analyzer.py                # Audio energy analysis
â”œâ”€â”€ visual_analyzer.py               # Visual saliency
â””â”€â”€ llm_analyzer.py                  # Hook extraction
```

### `/packages/db` - Database Migrations

```
packages/db/
â””â”€â”€ migrations/
    â”œâ”€â”€ 001_create_users.sql
    â”œâ”€â”€ 002_create_videos.sql
    â”œâ”€â”€ 003_create_clips.sql
    â”œâ”€â”€ 004_create_transcripts.sql
    â””â”€â”€ 005_create_exports.sql
```

---

## ğŸ”„ Video Processing Pipeline

```mermaid
graph LR
    A[User Uploads Video] --> B[Create Video Record]
    B --> C[Enqueue Celery Task]
    C --> D[Modal: Download Video]
    D --> E[Modal: WhisperX Transcription]
    E --> F[Modal: Speaker Detection]
    F --> G[Modal: Audio Analysis]
    G --> H[Modal: Visual Analysis]
    H --> I[Modal: Hook Extraction]
    I --> J[Backend: Virality Scoring]
    J --> K[Backend: Save Clips]
    K --> L[User Views Clips]
    L --> M[User Exports Clip]
    M --> N[Remotion Renders Video]
    N --> O[Upload to S3]
    O --> P[User Downloads]
```

---

## ğŸ¯ API Endpoints

### Authentication
- `POST /api/auth/login` - User login
- `POST /api/auth/signup` - User registration

### Videos
- `POST /api/videos/upload` - Upload video (URL or file)
- `GET /api/videos` - List user's videos
- `GET /api/videos/{video_id}` - Get video details

### Clips
- `GET /api/clips?video_id={id}` - List clips for video
- `GET /api/clips/{clip_id}` - Get clip details
- `POST /api/clips/{clip_id}/export` - Export clip

### Exports
- `GET /api/exports/{export_id}` - Get export status

### Health
- `GET /api/health` - Health check

Full API documentation available at `/docs` when running the backend.

---

## ğŸ§ª Testing

```bash
# Run all tests
pnpm test

# Frontend tests
cd apps/web
pnpm test

# Backend tests
cd apps/api
pytest

# Coverage report
pytest --cov=. --cov-report=html
```

---

## ğŸ“¦ Deployment

### Frontend (Vercel)

```bash
# Install Vercel CLI
pnpm add -g vercel

# Deploy
cd apps/web
vercel --prod
```

### Backend (Railway/Render)

```bash
# Build Docker image
docker build -f apps/api/Dockerfile -t viralvibe-api .

# Push to registry
docker push your-registry/viralvibe-api:latest
```

### Worker (Modal)

```bash
# Deploy Modal functions
cd packages/worker
modal deploy video_processor.py
```

---

## ğŸ”’ Security

- **Authentication**: JWT tokens with 1-hour expiry
- **Row-Level Security**: Supabase RLS policies
- **Input Validation**: Pydantic models for all inputs
- **Rate Limiting**: 100 requests/minute per user
- **CORS**: Restricted to frontend origin
- **SQL Injection**: Prevented via SQLAlchemy ORM
- **Secrets Management**: Environment variables only

---

## ğŸ“Š Virality Scoring Algorithm

Each clip receives a score (0-100) based on:

- **40% Hook Strength**: LLM analysis of transcript engagement
- **30% Audio Energy**: RMS energy levels and dynamic range
- **30% Visual Saliency**: Motion detection and visual interest

```python
virality_score = (0.4 * hook_score + 0.3 * audio_score + 0.3 * visual_score) * 100
```

---

## ğŸ› ï¸ Development

### Code Style

- **Python**: Black formatter, Ruff linter, mypy type checker
- **TypeScript**: ESLint, Prettier
- **Commits**: Conventional commits (feat, fix, refactor, etc.)

### Pre-commit Hooks

```bash
# Install pre-commit
pip install pre-commit
pre-commit install

# Run manually
pre-commit run --all-files
```

---

## ğŸ“ License

MIT License - See [LICENSE](LICENSE) file for details

---

## ğŸ¤ Contributing

Contributions are welcome! Please read [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

---

## ğŸ“§ Support

- **Documentation**: [docs.viralvibe.ai](https://docs.viralvibe.ai)
- **Email**: support@viralvibe.ai
- **Discord**: [Join our community](https://discord.gg/viralvibe)

---

## ğŸ™ Acknowledgments

- WhisperX for accurate transcription
- Pyannote.audio for speaker detection
- Remotion for video rendering
- Modal for GPU infrastructure

---

Made with â¤ï¸ by the ViralVibe Team
